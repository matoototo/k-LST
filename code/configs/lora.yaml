%YAML 1.2
---
dataset:
    name: "glue"
    subset: "stsb"

model:
    base_model: "roberta-large"
    model_type: "bert"
    lora:
        scaling_rank: 0
        rank: 8
        init_scale: 0.01
        layers: "query|key|value|dense"
        modules: ".*self|.*output|.*intermediate"
        buffer_original: False # Set true for side-lora

freeze:
    strategy: "none"

adapter:
    strategy: "none"

optimizer:
    name: "adamw"
    lr: 0.0003
    weight_decay: 0.01
    scheduler: "linear_decay_with_warmup"
    warmup_ratio: 0.06
    trainable_param_names: "classifier.dense.*|.*out_proj.*|.*LayerNorm.*|.*lora_[ab].*"

train:
    num_train_epochs: 5
    per_device_train_batch_size: 4
    per_device_eval_batch_size: 16
    output_dir: "results"
    evaluation_strategy: "steps"
    eval_steps: 500
    save_total_limit: 6
    load_best_model_at_end: True
    metric_for_best_model: 'pearsonr'

...
